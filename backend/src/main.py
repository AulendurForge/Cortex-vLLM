import json
from typing import List, Optional
from fastapi import FastAPI, Request, Depends, HTTPException
from fastapi.responses import JSONResponse, StreamingResponse, Response
from prometheus_client import generate_latest, CONTENT_TYPE_LATEST
from .metrics import REQ_COUNT, LATENCY, UPSTREAM_LATENCY, UPSTREAM_LATENCY_BY_UPSTREAM, STREAM_TTFT_SECONDS, UPSTREAM_SELECTED
from .config import Settings, get_settings
from .routes.openai import router as openai_router
from .routes.keys import router as keys_router
from .routes.admin import router as admin_router
from .routes.authn import router as authn_router
from .routes.orgs import router as orgs_router
from .routes.users import router as users_router
from .routes.models import router as models_router
from .middleware.ratelimit import check_rate_limit
import httpx
import asyncio
import redis.asyncio as redis_async
from sqlalchemy.ext.asyncio import create_async_engine, async_sessionmaker, AsyncSession
from .models import Base
from .health import poll_upstreams_periodically
from .otel import init_otel_if_enabled
from fastapi.middleware.cors import CORSMiddleware
import os
import uuid
from .state import set_model_registry as _set_model_registry

app = FastAPI(title="Cortex Gateway", version="0.1.0")

# Configure CORS at app creation time (cannot add middleware during startup)
try:
    _settings_for_cors = get_settings()
    if _settings_for_cors.CORS_ENABLED:
        allow = [o.strip() for o in _settings_for_cors.CORS_ALLOW_ORIGINS.split(",")] if _settings_for_cors.CORS_ALLOW_ORIGINS != "*" else ["*"]
        app.add_middleware(
            CORSMiddleware,
            allow_origins=allow,
            allow_credentials=True,
            allow_methods=["*"],
            allow_headers=["*"],
        )
except Exception:
    # Fail-open: if settings access fails at import-time, CORS just won't be enabled
    pass


@app.middleware("http")
async def request_id_middleware(request: Request, call_next):
    # Ensure every request has an x-request-id; propagate to response
    req_id = request.headers.get("x-request-id") or str(uuid.uuid4())
    request.state.req_id = req_id
    response = await call_next(request)
    try:
        response.headers.setdefault("x-request-id", req_id)
    except Exception:
        pass
    return response

@app.middleware("http")
async def metrics_middleware(request: Request, call_next):
    route = request.url.path
    with LATENCY.labels(route=route).time():
        # rate-limit check (fail-open on error)
        rl = await check_rate_limit(request)
        if rl is not None:
            response = rl
        else:
            response = await call_next(request)
    # Security headers
    try:
        if get_settings().SECURITY_HEADERS_ENABLED:
            if isinstance(response, Response):
                response.headers.setdefault("X-Content-Type-Options", "nosniff")
                response.headers.setdefault("X-Frame-Options", "DENY")
                response.headers.setdefault("Referrer-Policy", "strict-origin-when-cross-origin")
                response.headers.setdefault("X-XSS-Protection", "0")
                response.headers.setdefault("Cross-Origin-Opener-Policy", "same-origin")
                response.headers.setdefault("Cross-Origin-Resource-Policy", "same-origin")
    except Exception:
        pass
    REQ_COUNT.labels(route=route, status=str(response.status_code)).inc()
    return response

# Standardized error handlers to harmonize error JSON structure
@app.exception_handler(HTTPException)
async def http_exception_handler(request: Request, exc: HTTPException):
    rid = getattr(request.state, "req_id", request.headers.get("x-request-id", ""))
    content = {"error": {"code": exc.status_code, "message": exc.detail}, "request_id": rid}
    return JSONResponse(status_code=exc.status_code, content=content)

@app.exception_handler(Exception)
async def unhandled_exception_handler(request: Request, exc: Exception):
    rid = getattr(request.state, "req_id", request.headers.get("x-request-id", ""))
    content = {"error": {"code": 500, "message": "internal_server_error"}, "request_id": rid}
    return JSONResponse(status_code=500, content=content)

@app.middleware("http")
async def size_limit_middleware(request: Request, call_next):
    # Enforce max body size when Content-Length is present
    try:
        settings = get_settings()
        cl = request.headers.get("content-length")
        if cl and int(cl) > settings.REQUEST_MAX_BODY_BYTES:
            return JSONResponse(status_code=413, content={"error": "Request entity too large"})
    except Exception:
        pass
    return await call_next(request)

@app.get("/health")
async def health():
    return {"status": "ok"}

@app.get("/metrics")
async def metrics():
    data = generate_latest()
    return Response(content=data, media_type=CONTENT_TYPE_LATEST)

# OpenAI-compatible endpoints under /v1/*
app.include_router(openai_router, prefix="/v1")
app.include_router(keys_router, prefix="/admin")
app.include_router(admin_router, prefix="/admin")
app.include_router(authn_router, prefix="/auth")
app.include_router(orgs_router, prefix="/admin")
app.include_router(users_router, prefix="/admin")
app.include_router(models_router, prefix="/admin")


# Shared resources: httpx client, redis
http_client: httpx.AsyncClient | None = None
redis: redis_async.Redis | None = None
engine = None
SessionLocal: async_sessionmaker[AsyncSession] | None = None
_bg_health_task: asyncio.Task | None = None

 


@app.on_event("startup")
async def on_startup():
    global http_client, redis, _bg_health_task
    # Single shared client (connection pooling)
    http_client = httpx.AsyncClient(timeout=60.0)
    # Redis connection (optional)
    settings = get_settings()
    try:
        redis = redis_async.from_url(settings.REDIS_URL, encoding="utf-8", decode_responses=True)
    except Exception:
        redis = None
    # Database engine/session factory
    global engine, SessionLocal
    engine = create_async_engine(settings.DATABASE_URL, future=True, pool_pre_ping=True)
    SessionLocal = async_sessionmaker(engine, expire_on_commit=False)
    # Ensure schema exists in dev: create tables if they are missing
    try:
        async with engine.begin() as conn:
            await conn.run_sync(Base.metadata.create_all)
    except Exception:
        # In production, prefer Alembic migrations; this is best-effort.
        pass
    # Background health poller (optional)
    try:
        if settings.HEALTH_POLL_SEC > 0:
            _bg_health_task = asyncio.create_task(poll_upstreams_periodically(http_client))
    except Exception:
        _bg_health_task = None
    # OpenTelemetry (optional)
    init_otel_if_enabled()

    # Load persisted model registry from ConfigKV if present (best-effort)
    try:
        from sqlalchemy import select as _select  # type: ignore
        from .models import ConfigKV  # type: ignore
        if SessionLocal is not None:
            async with SessionLocal() as session:  # type: ignore
                res = await session.execute(_select(ConfigKV).where(ConfigKV.key == "model_registry"))
                row = res.scalar_one_or_none()
                if row and getattr(row, "value", None):
                    try:
                        data = json.loads(row.value)
                        if isinstance(data, dict):
                            _set_model_registry(data)
                    except Exception:
                        pass
    except Exception:
        pass

    # Ensure host-mapped directories exist (best-effort): models base and HF cache
    try:
        s = get_settings()
        if s.CORTEX_MODELS_DIR:
            os.makedirs(s.CORTEX_MODELS_DIR, exist_ok=True)
        if s.HF_CACHE_DIR:
            os.makedirs(s.HF_CACHE_DIR, exist_ok=True)
    except Exception:
        pass


@app.on_event("shutdown")
async def on_shutdown():
    global http_client, redis, engine, _bg_health_task
    if _bg_health_task:
        _bg_health_task.cancel()
        try:
            await _bg_health_task
        except Exception:
            pass
        _bg_health_task = None
    if http_client:
        await http_client.aclose()
        http_client = None
    if redis:
        try:
            await redis.close()
        except Exception:
            pass
        redis = None
    if engine:
        await engine.dispose()
        engine = None